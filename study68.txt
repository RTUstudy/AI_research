Page 1:
This is an Open Access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons. org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Copyright © 2021 The Author(s). Published by Vilnius Gediminas Technical University  *Corresponding author. E-mail:   jelena.titko@eka.edu.lv  Business, Management and Economics Engineering ISSN: 2669-2481 / eISSN: 2669-249X 2021 Volume 19 Issue 1: 170–179 https://doi.org/10.3846/bmee.2021.14201  ANALYSIS OF STUDENTS PERFORMANCE IN RELATION TO THE RESULTS OF STATE UNIFIED EXAM: THE CASE OF RUSSIAN UNIVERSITY  Anna SVIRINA   1 , Aleksey LOPATIN   2 , Jelena TITKO   3 *  1, 2 Kazan National Research Technical University Named after A.N. Tupolev, Kazan, Russia 3 EKA University of Applied Sciences, Riga, Latvia  Received 08 January 2021; accepted 28 January 2021  Abstract.   Purpose   – Considering the limited number of studies covering the topic, the goal is to check the existence of the correlation between the results of Russia’s Unified State Exam and performance at the university.  Research methodology   – the article uses quantitate analysis (regression) of the student perfor- mance on a sample of 4664 students. To provide statistical evaluation, the authors use SPSS Statistics software.  Findings   – the research suggests, that results of unified state exam and individual students scores, awarded by the university under restrictions, are non-efficient in terms of predicting student performance. On the opposite, students’ performance during their first semester is a good predic- tor for the whole period of academic studies. As existing results of testing such hypotheses are inconsistent, the research provides value to the field of educational research.  Research limitations   – data for research refer to only Kazan National Research Technical Univer- sity named after A. N. Tupolev (KNRTU-KAI).  Practical implications   – the research clearly indicate, that the universities cannot rely solely on the unified state exam during admission; they are to use different assessment tools to ensure future academic performance and lower dropouts rate.  Originality/Value   – There is a gap in the investigation the link between secondary education and higher education performance.  Keywords:   students’ performance, admission criteria, Russia Unified State Exam.  JEL Classification:   I21, I23.  Introduction  Prediction of students’ performance is quite a popular topic for investigation because this information can help “to design effective mechanisms that improve academic results and avoid dropout” (Rastrollo-Guerrero et al., 2020), “to reach the highest level of quality in

Page 2:
Business, Management and Economics Engineering, 2021, 19(1): 170–179   171  the higher education system” (Sembiring et al., 2011), to properly “select among candi- dates” (Tatar & Düştegör, 2020), as well as to evaluate institutional performance (Alyahyan & Düştegör, 2020). Besides, predicting students’ performance “creates opportunities to improve educational outcomes” (Hellas et al., 2018) and also can help “potentially weak students in overcoming educational challenges” (Tatar & Düştegör, 2020). This, in turn, will allow reducing the dropout rate in higher education. In Europe, the question about reducing the number of early leavers is on the current agenda. The current goal of the European Commission within the strategic framework for European cooperation in education and training (European Commission, 2020), among others, is “the rate of early leavers from education and training aged 18–24 should be below 10%” (European Commission, 2020). This indicator in the EU varies from 3.0% to 17.3% in 2019 (Eurostat, 2019). In turn, in Russia the rate of early university dropouts is limited by the Ministry of Higher Education – the university can lose not more, than 10% of its students (Gru- zdev et al., 2010), and it makes the task of recruiting the “right students” even more challenging. Various predictors of students’ performance have been investigated by researchers (Sul- phey et al., 2018; Hellas et al., 2018; Zivcic-Becirevic et al., 2017). In the current study, the authors look at the relationship between admission criteria and students’ results. The case of the Russian educational system, in particular regarding Russia’s Unified State Exam, has been considered. The goal of the research is to check the existence of the correlation between the results of Russia’s Unified State Exam and performance at the university. The research was based on data about more than 6000 students representing different study programmes at Kazan State Technical University named after A. N. Tupolev (KNRTU-KAI). Students’ performance was proxied by the Grade Point Average in each particular study semester and for the whole study period. The null hypothesis is stated, as follows: H0: There is a statistically significant positive relationship between the results in Russia’s Unified State Exam and students’ performance. The authors assume that other factors should also be taken into consideration for making a reliable forecast. To process the data, the authors have used SPSS Statistics software 22.0 to run simple and multiple regression analysis alongside with the graph analysis of the interrelation between stu- dent’s academic performance and the results of unified state exam on entering the university. As it appeared from the undertaken analysis, the hypothesis is not supported. Though the influence of the unified state exam results onto students’ performance at the Kazan National Research Technical University is statistically significant, it is very low. Thus, one can’t con- sider such results as a good predictor of future student’s academic performance.  1. Exploratory measures to predict students’ performance  A comprehensive review on predicting students’ performance was made by Shahiri et al. (2015), and the results yielded several groups of most important factors, such as students’ demographic attributes, psychometric factors, extra-curricular activities, social interaction

Page 3:
172   A. Svirina et al. Analysis of students performance in relation to the results of state unified exam...  network. The authors also mentioned the Grade Point Average (GPA) as the most frequently used variable for predicting students’ performance. Hellas et al. (2018) group performance predictors into five categories: demographic (e.g., age, gender), personality (e.g., self-efficacy, self-regulation), academic (e.g., high-school per- formance, course performance), behavioral and institutional (e.g., high-school quality, teach- ing approach). Students’ demographic attributes (gender, age, family background) concerning perfor- mance are investigated in many studies (Sembiring et al., 2011; Aziz & Awlla, 2019). Some researchers also highlight such factors, as time efforts and students’ attitude towards study process (Sembiring et al., 2011), students’ self-efficacy and motivation (Beharu, 2018), per- sonal traits, such as extraversion, social adjustment and others (Zivcic-Becirevic et al., 2017), parents’ occupation (Ramesh et al., 2013; Khan et al., 2015), disabilities and study habits (Olufemi et al., 2018). Hughes et al. (2017) stated that “students who are wage-earning or self-employed on admission ... are more likely to succeed”. Another factor affecting students’ performance is a schedule of examination – van der Vinne et al. (2015) investigated the cor- relation between students’ chronotype and examination performance. The academic interest of the authors of the paper is to reveal or confirm the non-existence of the link between the admission criteria and students’ academic performance. According to OECD survey “national/central examinations, taken towards the end of upper secondary education ... are the most widely used examinations/tests for entry into first-degree tertiary programmes” (OECD, 2017). The attempts to investigate the link between examination results at secondary school and students’ performance have been made (Silva et al., 2020; Goldstein & Thomas, 1996). However, it should be mentioned that most of the studies have been conducted in the field on medical education (Curtis et al., 2007; Al-Rukban et al., 2010; Yousafzai & Jamil, 2019). The authors of the paper agree with Silva et al. (2020) in their statement that “The link be- tween secondary education and higher education achievements remains understudied”. In particular, this gap exists in the field of business education. Besides, from the authors’ viewpoint, admission results should not be solely dependent on examination scores. There is a piece of empirical evidence showing that students’ personal traits, such as organisational skills, intrinsic motivation (Zivcic-Becirevic et al., 2017) are very important for educational success. For instance, Harvard admission officers take into account personality, intellectual curi- osity, character, intelligence, perspective, and skill set of the candidates. In Cambridge, the applicants are expected to be able “to think critically and independently”, and to have “self- discipline, motivation, commitment...” (University of Cambridge, 2020). One of the main findings presented in the report from the Council of Graduate Schools (Kent & McCarthy, 2016) is that “Graduate institutions are calling for more data that dem- onstrate the link between admissions criteria and student success”. The authors of the current research strongly believe that there is a need for such data also in the Russian Federation, and this paper contributes to the formation of such a database.

Page 4:
Business, Management and Economics Engineering, 2021, 19(1): 170–179   173  2. Admission process Russian Universities  Russian educational system includes three educational levels. The first one is the school level (11 years of education), which is required for everyone. After the 9 th   year of school education, a person can transfer to the professional education institutions (mainly colleges and profes- sional schools. After completion of the school level, a graduate can enter higher education institutions based on results of the Unified State Exam. A schoolchild can choose as many exams as he or she wishes, and 3 positive results (above the given threshold) are required to be admitted competing with other applicants to become an undergraduate student in s cer- tain university. After completion of undergraduate studies, a person can continue education on the post-graduate level, choosing any educational program on the master level. The Unified State Exam can be taken once in a year, and the first attempt has to happen during the last year of school studies (in the 11 th   grade). After checking the results, they are inserted in a state record system, and after application each university requests those results to check if this person is eligible to enrol in higher educational programs – if the results are below the specific threshold, a person is automatically withdrawn from enrollment. Since 2009 Russian universities are obliged to use Unified State Exam results as almost the only prerequisite to admission – each school graduate needs to submit 3 scores of this exam to the university (usually, two of them are Mathematics and Russian language). Those 3 scores are summarised, and the enrolment list reflects the rank of the student based on this sum. The ones, who have a higher integral score, are admitted to the university; the others are left out. The exception from this rule exist, but are rare – for instance, a conservatory can arrange a preliminary audition, or a theater or art academy can add a so-called “creative exam” where is the ability of a candidate to perform or draw will be checked out. This system is more or less the same for all post-Soviet countries with an exception to the Baltic States (Semyonov et al., 2015). As this system has been a subject for criticism, later the universities could add 10 points to this integral score, based on the personal achievements of the potential student. These 10 points do not change the situation significantly (the integral Unified State Exam score can be 300 points, 100 per each of 3 exams), but in case of equal scores, it allowed universities to make a choice based on their own criteria. Yet, the argument around continues and the higher education system does not have a consensus on how good or bad is the Unified State Exam based admission system. Russian researchers have attempted to investigate the link between the results of Russia’s Uni- fied State Exam (USE) and students’ performance (Stanko et al., 2016; Khavenson & Solovyova, 2014; Zamkov & Peresetsky, 2013). These studies confirmed a predictive capacity of USE. Based on these studies, almost every Russian monitoring and ranking system assesses average entry USE point as one of the measures for the university’s quality of performance. However, the number of investigations is quite limited to judge the reliability, leaving a room for this study.  3. Research methodology  The current study is based upon the admission and performance data collected longitude by one of the leading Russian technical universities, Kazan National Research Technical Uni- versity. The data sample included average USE point submitted in the process of admission

Page 5:
174   A. Svirina et al. Analysis of students performance in relation to the results of state unified exam...  to the university, the individual points (up to 10) awarded by the university upon admission, performance during each exam session (twice a year) and overall university performance. This data was collected for 4664 students of Kazan National Research Technical University, who are enrolled in their 2–4 years of studies on the offered undergraduate programs. The sample is balanced in terms of program structure within the university – 1336 are the stu- dents of Aviation, Transport and Energy Institute (the biggest one), 653 – in the Automa- tion and Electronic Equipment Building Institute, 1063 – in the Technical Cybernetics and Information Security Institute, 465 – in the Engineering Economics and Entrepreneurship Institute, 995 – in the Radioelectronics and Telecommunication Institute and 152 – in Phys- ics and Mathematics faculty. The study used regression analysis (   Chatterjee   et al., 2000) performed by SPSS statistics software, alone with graph analysis implemented with the same software. By these means, the authors have tested the following three hypotheses. 1. Students with higher Unified State Exam results at the point of admission to the uni- versity demonstrate better performance at the university. 2. Students with higher individual points awarded by the university upon admission dem- onstrate better performance at the university. 3. Students with the higher performance during the first university exam session, dem- onstrate better performance at the university. Regression models have used average performance rate at the university during the exam sessions throughout education process as the dependent variable, while average Unified State Exam result, individual points and average result during the first session were used as inde- pendent variables.  4. Results  The results of testing the first hypothesis in accordance with the described procedure indicate that results of USE can explain, on average, only 6% of the variance in individual student’s performance at the university. The variance explained by the individual points, received by the student during the admission process (hypothesis 2) is also low – 7.5% – though it is a bit higher than in case of USE. When hypothesis 1 and 2 were combined, and the authors performed multiple linear regression analysis, model accuracy increased, and together these two factors explain 21% of the variance in student’s performance at the university. Still, as the university has to enrol student based solely on these two factors, 21% seems not enough to predict future student performance; thus, hypotheses 1 and 2 are not supported in case of Kazan National Research Technical University (though the results appeared to be statisti- cally significant). On the opposite, hypothesis 3 was supported. Student’s performance during the first uni- versity exam session explains 53.2% of the variance in overall performance at the university. This is 8.5 times higher than the quality of predictions made on the basis of USE results, and 2.5 times more accurate in case one uses multiple regression model with USE results and individual points as independent variables. Based on this finding, one can argue that academic success at the university requires something different compared to the successful

Page 7:
176   A. Svirina et al. Analysis of students performance in relation to the results of state unified exam...  Figure 1. Variation of student performance in relation to USE score upon admission Table 2. Regression analysis of USE results (independent variable) as a predictor of university academic performance (dependent variable) – by institute Institute/Faculty Academic performance variance explained (by predicting factor, linear regression) Average USE score Individual points Average performance during 1   st   exam session Aviation, Transport and Energy Institute 2.1%   7.1%   57.4% Automation and Electronic Equipment Building Institute 0.6%   12.3%   45.5% Engineering Economics and Entrepreneurship Institute 3.1%   0.9%   58.4% Technical Cybernetics and Information Security Institute 6.6%   11.9%   59.6% Radio electronics and Telecommunication Institute 2.1%   3.8%   51.6% Physics and Mathematics faculty   1.3%   18.5%   68.1% for their academic peers with lower scores – if their USE score upon admission is above 95, the predictive power of their first exam session results drops down to 19.7%. Finally, it seemed logical to test the achieved results for consistency in terms of chosen study programs. To do so, the authors had split the sample by the institute, chosen by the students (see Table 2).

Page 8:
Business, Management and Economics Engineering, 2021, 19(1): 170–179   177  The table clearly indicates that USE predictive power differs 10 times across Institutes – while for those choosing Aviation, Transport and Energy Institute it is average and explains about 2% of the variation, for IT-majors USE results would be three times more accurate to predict performance. Same is true for the individual points, where the predictive power is very low in case of economists (0.9%) and is twenty times higher for physics and mathemat- ics majors (18.5%). Yet, those numbers are still low, and the fact that hypotheses 1 and 2 are not supported, are confirmed. At the same time, as we have seen before, the results of the first exam session are a very good predictor of academic performance throughout a student’s life at the university. With the exception of just one institute, the results demonstrated during the first semester deter- mine final academic success by more than 50%. Thus, hypothesis 3 was supported.  Conclusions  The results achieved by this study support some existing findings. First, we have proven, that academic success during the first semester encourages students to do well throughout the university, and vice versa, and it confirms findings by both Hellas et al. (2018) and Tatar and Düştegör (2020). It seems significant that the universities should clearly indicate to the students, that for their academic success on the tertiary level it is almost irrelevant, how good or bad they were during their school years. From the practical point of view, encouraging students to get on track in the university from the very beginning should lead to reduced dropout rate, which fits into the goals of national education strategies – both in Europe and in post-Soviet countries. Also, the study had confirmed some of the previous findings, in- cluding such factors, as time efforts and students’ attitude towards study process (Sembiring et al., 2011), study habits (Olufemi et al., 2018; Hughes et al., 2017). Other findings of this research differ from that one can find in existing literature. First of all, the predictive power of the Unified State Exam was confirmed to be low, and these results differ from those achieved by Stanko et al. (2016), Khavenson and Solovyova (2014) or Zamkov and Peresetsky (2013). Hence, using USE results as the major admission indicator can possibly drive out best performing students – as USE predictive power drops even more for the students with high scores. Same is true for individual points, awarded based on objec- tive results. Though individual points are a better predictor of academic performance, than USE scores, the relevance to future performance is still low. This may be a consequence of the restrictions applied to Russian universities when they choose what they can award points for. Finally, as soon as the students is enrolled, the university seems to be consistent in developing his or her skills throughout the study process. Though university requirements seem to be incon- sistent with what is required on school level, the first semester in the university clearly defines how well will the student do later – with the exception of those with extremely high USE scores. Based on these findings, the authors of the paper suggest that policymakers revise ad- mission criteria that are now solely based on the Unified State Exam results. The successful examples provided by worldwide known Universities, such as Harvard Business School and Cambridge. Tertiary education requires skills and motivation which is different from the one relevant at the school level; due to that; it seems logical that the universities which have

Page 6:
Business, Management and Economics Engineering, 2021, 19(1): 170–179   175  completion of the Unified State Exam, and these qualities are a better predictor for future students’ academic success. It also seems no exaggeration to mention, that university educa- tional system is solid in terms of creating student competence, and if the student understands the requirements during the first 4 months, it is highly likely he or she would be academically successful – no matter how high or low they have scored at USE. To confirm these findings, the authors further detailed the study by assessing the hypoth- esis that the predictive power of USE results would increase if only higher scores would be taken into account. To test this hypothesis, the sample was analysed for different USE scores with a range of 5 points on a 100-point scale. The results are in Table 1, both USE scores, and university academic performance variance explained. The results indicate, that USE score serves best as a predictor of future (low) academic performance when the future student passed the unified exam and earned a great that is just slightly above the threshold. On the opposite, the higher is USE admission score, the lower is the probability that student’s quality of the performance would be the same at the university level. The graph in Figure 1 illustrates this finding. Table 1 also indicates that the quality of individual points as a predictor of future aca- demic performance leads to the same results as we have described above with the USE score (independent variable). This hypothesis was tested for each amount of individual points (from 1 to 10), and variance explained was in each case below 10%. Though for a score, that changes the chance of a person to be admitted to the university, by 3%, the predictive power of up to 10% is relatively high; still, in the context of this research the authors are to reject hypothesis 2, and confirm, that both USE score and individual points can’t be considered a good predictor of academic performance. It is also interesting, that for high score USE stu- dents the first exam session is a much worse predictor of their academic performance, than Table 1. Regression analysis of USE results (independent variable) as a predictor of university academic performance (dependent variable) – by USE score USE score Academic performance variance explained (by predicting factor, linear regression) Average USE score   Individual points   Average performance during 1 st   exam session Above 45   16.3%   7.6%   51.7% Above 50   12.5%   6.8%   48.9% Above 55   9.1%   6.0%   47.7% Above 60   7.2%   5.5%   47.8% Above 65   5.9%   4.8%   48.0% Above 70   4.5%   3.5%   50.5% Above 75   3.7%   3.3%   51.7% Above 80   1.9%   3.8%   53.6% Above 85   3.6%   3.4%   53.3% Above 90   0.1%   1.6%   44.3% Above 95   0%   0%   19.7%

Page 9:
178   A. Svirina et al. Analysis of students performance in relation to the results of state unified exam...  more freedom in defining their admission procedures do better than the ones who experi- ence such restrictions. The current research has a big potential for expansion, using the data on the academic performance of students’ at other Russian universities.  References  Al-Rukban, M. O., Munshi, F. M., Abdulghani, H. M., & Al-Hoqail, I. (2010). The ability of the pre- admission criteria to predict performance in a Saudi medical school.   Saudi Medical Journal ,   31 (5), 560–564. Alyahyan, E., & Düştegör, D. (2020). Predicting academic success in higher education: literature review and best practices.   International Journal of Educational Technology in Higher Education ,   17 (1), 3. https://doi.org/10.1186/s41239-020-0177-7 Aziz, S. M., & Awlla, A. H. (2019). Performance analysis and prediction student performance to build effective student using data mining techniques.   UHD Journal of Science and Technology ,   3 (2), 10–15. https://doi.org/10.21928/uhdjst.v3n2y2019.pp10-15 Beharu, W. T. (2018). Psyhological factors affecting students academic performance among freshman psychology students in Dire Dawa University.   Journal of Education and Practice ,   9 (4), 59–65. Chatterjee, S., Hadi, A. S., & Price, B. (2000). Regression analysis by example (3 rd   ed.). John Wiley & Sons, New York. Curtis, D. A., Lind, S. L., Plesh, O., & Finzen, F. C. (2007). Correlation of admissions criteria with aca- demic performance in dental students.   Journal of Dental Education ,   71 (10), 1314–1321. https://doi.org/10.1002/j.0022-0337.2007.71.10.tb04395.x European Commission. (2020).   Education and training . https://ec.europa.eu/education/policies/euro- pean-policy-cooperation/et2020-framework_en Eurostat. (2019).   Early leavers from education and training . https://ec.europa.eu/eurostat/statistics-ex- plained/index.php/Early_leavers_from_education_and_training Gruzdev, I., Gorbunova, E., & Frumin, I. (2010)   Students need help, not exclusion . https://iq.hse.ru/ news/177668602.html Goldstein, H., & Thomas, S. (1996). Using examination results as indicators of school and college per- formance.   Journal of the Royal Statistical Society: Series A (Statistics in Society) ,   159 (1), 149–163. https://doi.org/10.2307/2983475 Hellas, A., Ihantola, P., Petersen, A., Ajanovski, V. V., Gutica, M., Hynninen, T., Knutas, A., Leinonen, J., Messom, Ch., & Liao, S. N. (2018, July). Predicting academic performance: A systematic literature review. In   Proceedings Companion of the 23 rd   Annual ACM Conference on Innovation and Technology in Computer Science Education   (pp. 175–199). https://doi.org/10.1145/3293881.3295783 Hughes, C., Gremillion, H., Bridgman, G., Ashley, P., & McNabb, D. (2017). Student selection process effectiveness: Correlations between task performance and undergraduate success.   Aotearoa New Zealand Social Work ,   29 (4), 32–48. https://doi.org/10.11157/anzswj-vol29iss4id385 Kent, J. D., & McCarthy, M. T. (2016).   Holistic review in graduate admissions:   A Report from the Council of Graduate Schools . Washington, DC: Council of Graduate Schools. https://cgsnet.org/ckfinder/ userfiles/files/CGS_HolisticReview_final_web.pdf Khan, B., Khiyal, M. S. H., & Khattak, M. D. (2015). Final grade prediction of secondary school student using decision tree.   International Journal of Computer Applications ,   115 (21), 32–36. https://doi.org/10.5120/20278-2712 Khavenson, T., & Solovyova, A. (2014). Studying the relation between the Unified State Exam points and higher education performance.   Educational Studies ,   1 , 176–199. https://ideas.repec.org/a/nos/ voprob/2014i1p176-199.html

Page 10:
Business, Management and Economics Engineering, 2021, 19(1): 170–179   179  OECD. (2017).   Education at a Glance 2017 . https://www.oecd-ilibrary.org/docserver/eag-2017-34-en.pdf? expires=1604676581&id=id&accname=guest&checksum=91EE7E047E0C52CFCFDCAA26A50201E2 Olufemi, O. T., Adediran, A. A., & Oyediran, W. O. (2018). Factors affecting students’ academic per - formance in colleges of education in Southwest, Nigeria.   British Journal of Education ,   6 (10), 43–56. Ramesh, V. A. M. A. N. A. N., Parkavi, P., & Ramar, K. (2013). Predicting student performance: A statistical and data mining approach.   International Journal of Computer Applications ,   63 (8), 35–39. https://doi.org/10.5120/10489-5242 Rastrollo-Guerrero, J. L., Gómez-Pulido, J. A., & Durán-Domínguez, A. (2020). Analysing and predict- ing students’ performance by means of machine learning: A review.   Applied Sciences ,   10 (3), 1042. https://doi.org/10.3390/app10031042 Sembiring, S., Zarlis, M., Hartama, D., Ramliana, S., & Wani, E. (2011, April). Prediction of student academic performance by an application of data mining techniques.   International Conference on Management and Artificial Intelligence IPEDR ,   6 (1), 110–114. Semyonov, D., Isaeva, N., Platonova, D., & Kobtseva, A. (2015)   Student accountability in Post-Soviet coun- tries . https://unesdoc.unesco.org/in/documentViewer.xhtml?v=2.1.196&id=p::usmarcdef_000025 9570&file=/in/rest/annotationSVC/DownloadWatermarkedAttachment/attach_import_8a4052fd- 018a-4379-9401-601e1b771531%3F_%3D259570eng.pdf&locale=en&multi=true&ark=/ark:/48223/ pf0000259570/PDF/259570eng.pdf#%5B%7B%22num%22%3A189%2C%22gen%22%3A0%7D%2C %7B%22name%22%3A%22XYZ%22%7D%2C0%2C792%2Cnull%5D Shahiri, A. M., Husain, W., & Rashid, N. A. (2015). A review on predicting student’s performance using data mining techniques.   Procedia Computer Science ,   72 , 414–422. https://doi.org/10.1016/j.procs.2015.12.157 Silva, M. C., Camanho, A. S., & Barbosa, F. (2020). Benchmarking of secondary schools based on Stu- dents’ results in higher education.   Omega ,   95 , 102119. https://doi.org/10.1016/j.omega.2019.102119 Stanko, T., Valiev, M., & Johnston, D. M. (2016). Case study: Using Russia’s Unified State Exam and other admission metrics as a predictor of academic performance at an IT University. In   ASEE’s 123 rd Annual Conference . https://www.researchgate.net/publication/307168473_Case_Study_Using_Rus- sia’s_Unified_State_Exam_and_other_admission_metrics_as_a_predictor_of_academic_perfor- mance_at_an_IT_University Sulphey, M. M., Al-Kahtani, N. S., & Syed, A. M. (2018). Relationship between admission grades and academic achievement.   Journal of Entrepreneurship and Sustainability Issues ,   5 (3), 648–658. https://doi.org/10.9770/jesi.2018.5.3(17) Tatar, A. E., & Düştegör, D. (2020). Prediction of Academic performance at undergraduate graduation: Course grades or grade point average?   Applied Sciences ,   10 (14), 4967. https://doi.org/10.3390/app10144967 University of Cambridge. (2020).   Undergraduate study.   https://www.undergraduate.study.cam.ac.uk/ applying/what-are-we-looking-for van der Vinne, V., Zerbini, G., Siersema, A., Pieper, A., Merrow, M., Hut, R. A., Roenneberg, T., & Kan- termann, T. (2015). Timing of examinations affects school performance differently in early and late chronotypes.   Journal of Biological Rhythms ,   30 (1), 53–60. https://doi.org/10.1177/0748730414564786 Yousafzai, I. I., & Jamil, B. (2019). Relationship between admission criteria and academic performance: A correlational study in nursing students.   Pakistan Journal of Medical Sciences ,   35 (3), 858–861. https://doi.org/10.12669/pjms.35.3.217 Zamkov, O., & Peresetsky, A. (2013). Russian Unified National Exams (UNE) and academic perfor- mance of ICEF HSE students.   Applied Econometrics ,   30 (2), 93–114. Zivcic-Becirevic, I., Smojver-Azic, S., & Martinac Dorcic, T. (2017). Predictors of University students’ academic achievement: A prospective study.   Društvena istraživanja: časopis za opća društvena pi- tanja ,   26 (4), 457–476. https://doi.org/10.5559/di.26.4.01

